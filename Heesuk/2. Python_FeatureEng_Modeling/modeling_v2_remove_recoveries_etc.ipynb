{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 80)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final.df.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>mths_since_recent_revol_delinq</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>num_actv_bc_tl</th>\n",
       "      <th>num_bc_sats</th>\n",
       "      <th>num_bc_tl</th>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>fico_range_mean</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>emp_length_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14740.615375</td>\n",
       "      <td>14.047924</td>\n",
       "      <td>445.564543</td>\n",
       "      <td>7.432490e+04</td>\n",
       "      <td>18.931042</td>\n",
       "      <td>0.326485</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>38.589950</td>\n",
       "      <td>11.683355</td>\n",
       "      <td>0.226445</td>\n",
       "      <td>1.590229e+04</td>\n",
       "      <td>52.740852</td>\n",
       "      <td>24.888360</td>\n",
       "      <td>12636.221310</td>\n",
       "      <td>2478.097381</td>\n",
       "      <td>2.624044</td>\n",
       "      <td>560.785900</td>\n",
       "      <td>3799.395097</td>\n",
       "      <td>641.761105</td>\n",
       "      <td>610.148025</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>230.022100</td>\n",
       "      <td>1.334342e+05</td>\n",
       "      <td>1.050920</td>\n",
       "      <td>2.714855</td>\n",
       "      <td>0.873715</td>\n",
       "      <td>1.915005</td>\n",
       "      <td>19.761910</td>\n",
       "      <td>3.351007e+04</td>\n",
       "      <td>70.205415</td>\n",
       "      <td>1.262295</td>\n",
       "      <td>2.713755</td>\n",
       "      <td>5505.012450</td>\n",
       "      <td>61.995210</td>\n",
       "      <td>3.119424e+04</td>\n",
       "      <td>1.167065</td>\n",
       "      <td>1.669000</td>\n",
       "      <td>2.407435</td>\n",
       "      <td>4.898570</td>\n",
       "      <td>12652.200355</td>\n",
       "      <td>9305.872275</td>\n",
       "      <td>61.043219</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>16.915020</td>\n",
       "      <td>123.496620</td>\n",
       "      <td>177.572560</td>\n",
       "      <td>12.592685</td>\n",
       "      <td>7.572270</td>\n",
       "      <td>1.583020</td>\n",
       "      <td>23.051050</td>\n",
       "      <td>7.020060</td>\n",
       "      <td>41.13807</td>\n",
       "      <td>0.522660</td>\n",
       "      <td>3.702345</td>\n",
       "      <td>4.719860</td>\n",
       "      <td>7.997870</td>\n",
       "      <td>5.726970</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>2.271730</td>\n",
       "      <td>94.162227</td>\n",
       "      <td>46.697567</td>\n",
       "      <td>0.142080</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>20540.207830</td>\n",
       "      <td>695.489473</td>\n",
       "      <td>12.822720</td>\n",
       "      <td>5.946410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8752.102580</td>\n",
       "      <td>4.954058</td>\n",
       "      <td>262.118049</td>\n",
       "      <td>7.020791e+04</td>\n",
       "      <td>11.675555</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>0.964933</td>\n",
       "      <td>21.663606</td>\n",
       "      <td>5.529451</td>\n",
       "      <td>0.631672</td>\n",
       "      <td>2.076584e+04</td>\n",
       "      <td>24.399791</td>\n",
       "      <td>12.065927</td>\n",
       "      <td>9763.746055</td>\n",
       "      <td>2626.966900</td>\n",
       "      <td>13.561922</td>\n",
       "      <td>1410.832467</td>\n",
       "      <td>6281.502295</td>\n",
       "      <td>89.661439</td>\n",
       "      <td>169.790827</td>\n",
       "      <td>0.152829</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>1775.613015</td>\n",
       "      <td>1.492501e+05</td>\n",
       "      <td>1.189981</td>\n",
       "      <td>2.953508</td>\n",
       "      <td>1.056642</td>\n",
       "      <td>2.005857</td>\n",
       "      <td>25.708152</td>\n",
       "      <td>4.046119e+04</td>\n",
       "      <td>23.289368</td>\n",
       "      <td>1.358994</td>\n",
       "      <td>2.337575</td>\n",
       "      <td>5174.260522</td>\n",
       "      <td>19.674457</td>\n",
       "      <td>3.094635e+04</td>\n",
       "      <td>1.683867</td>\n",
       "      <td>2.932574</td>\n",
       "      <td>2.615008</td>\n",
       "      <td>3.280455</td>\n",
       "      <td>15288.478032</td>\n",
       "      <td>14277.046880</td>\n",
       "      <td>28.251856</td>\n",
       "      <td>0.104616</td>\n",
       "      <td>943.077677</td>\n",
       "      <td>53.847389</td>\n",
       "      <td>94.626771</td>\n",
       "      <td>15.829046</td>\n",
       "      <td>8.539039</td>\n",
       "      <td>1.974375</td>\n",
       "      <td>30.106178</td>\n",
       "      <td>6.059382</td>\n",
       "      <td>21.84772</td>\n",
       "      <td>1.333422</td>\n",
       "      <td>2.268906</td>\n",
       "      <td>2.960616</td>\n",
       "      <td>4.750692</td>\n",
       "      <td>3.267695</td>\n",
       "      <td>0.062636</td>\n",
       "      <td>0.485539</td>\n",
       "      <td>1.894223</td>\n",
       "      <td>8.728537</td>\n",
       "      <td>36.143285</td>\n",
       "      <td>0.386451</td>\n",
       "      <td>0.436312</td>\n",
       "      <td>20559.740281</td>\n",
       "      <td>30.408820</td>\n",
       "      <td>6.669401</td>\n",
       "      <td>3.699005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.310000</td>\n",
       "      <td>14.010000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>662.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.640000</td>\n",
       "      <td>257.200000</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.936000e+03</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5411.899123</td>\n",
       "      <td>786.697500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.790000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.936775e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.806750e+03</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2213.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.360000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3009.000000</td>\n",
       "      <td>1327.000000</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.300000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>12625.000000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>382.360000</td>\n",
       "      <td>6.300000e+04</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.108700e+04</td>\n",
       "      <td>53.300000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10080.124295</td>\n",
       "      <td>1632.645000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>652.410000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>645.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.298800e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.232000e+04</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4224.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.320000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6807.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>64.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>97.900000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14400.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>587.550000</td>\n",
       "      <td>9.000000e+04</td>\n",
       "      <td>24.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.940200e+04</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>17291.974973</td>\n",
       "      <td>3179.242500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>449.050000</td>\n",
       "      <td>4799.417500</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.972862e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.353500e+04</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7206.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>3.860000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17392.250000</td>\n",
       "      <td>11166.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26500.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>1717.630000</td>\n",
       "      <td>1.099920e+07</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.190046e+06</td>\n",
       "      <td>182.800000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>62687.030890</td>\n",
       "      <td>27687.030000</td>\n",
       "      <td>1188.830000</td>\n",
       "      <td>37153.460000</td>\n",
       "      <td>41096.620000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>199433.000000</td>\n",
       "      <td>3.258254e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>1.547285e+06</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>301210.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>1.314900e+06</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>497484.000000</td>\n",
       "      <td>293031.000000</td>\n",
       "      <td>190.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>249925.000000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>202.00000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>760000.000000</td>\n",
       "      <td>847.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loan_amnt       int_rate    installment    annual_inc            dti    delinq_2yrs  inq_last_6mths  mths_since_last_delinq       open_acc        pub_rec     revol_bal     revol_util  \\\n",
       "count  200000.000000  200000.000000  200000.000000  2.000000e+05  200000.000000  200000.000000   200000.000000           200000.000000  200000.000000  200000.000000  2.000000e+05  200000.000000   \n",
       "mean    14740.615375      14.047924     445.564543  7.432490e+04      18.931042       0.326485        0.694805               38.589950      11.683355       0.226445  1.590229e+04      52.740852   \n",
       "std      8752.102580       4.954058     262.118049  7.020791e+04      11.675555       0.886051        0.964933               21.663606       5.529451       0.631672  2.076584e+04      24.399791   \n",
       "min       500.000000       5.310000      14.010000  0.000000e+00      -1.000000       0.000000        0.000000                0.000000       0.000000       0.000000  0.000000e+00       0.000000   \n",
       "25%      8000.000000      10.640000     257.200000  4.500000e+04      12.350000       0.000000        0.000000               22.000000       8.000000       0.000000  5.936000e+03      34.600000   \n",
       "50%     12625.000000      13.490000     382.360000  6.300000e+04      18.330000       0.000000        0.000000               36.000000      11.000000       0.000000  1.108700e+04      53.300000   \n",
       "75%     20000.000000      16.990000     587.550000  9.000000e+04      24.830000       0.000000        1.000000               55.000000      14.000000       0.000000  1.940200e+04      71.600000   \n",
       "max     40000.000000      30.990000    1717.630000  1.099920e+07     999.000000      21.000000        8.000000              202.000000      80.000000      86.000000  1.190046e+06     182.800000   \n",
       "\n",
       "           total_acc    total_pymnt  total_rec_int  total_rec_late_fee     recoveries  last_pymnt_amnt  last_fico_range_high  last_fico_range_low  collections_12_mths_ex_med  acc_now_delinq  \\\n",
       "count  200000.000000  200000.000000  200000.000000       200000.000000  200000.000000    200000.000000         200000.000000        200000.000000               200000.000000   200000.000000   \n",
       "mean       24.888360   12636.221310    2478.097381            2.624044     560.785900      3799.395097            641.761105           610.148025                    0.018800        0.005245   \n",
       "std        12.065927    9763.746055    2626.966900           13.561922    1410.832467      6281.502295             89.661439           169.790827                    0.152829        0.079168   \n",
       "min         2.000000       0.000000       0.000000            0.000000       0.000000         0.000000              0.000000             0.000000                    0.000000        0.000000   \n",
       "25%        16.000000    5411.899123     786.697500            0.000000       0.000000       318.790000            564.000000           560.000000                    0.000000        0.000000   \n",
       "50%        23.000000   10080.124295    1632.645000            0.000000       0.000000       652.410000            649.000000           645.000000                    0.000000        0.000000   \n",
       "75%        32.000000   17291.974973    3179.242500            0.000000     449.050000      4799.417500            714.000000           710.000000                    0.000000        0.000000   \n",
       "max       173.000000   62687.030890   27687.030000         1188.830000   37153.460000     41096.620000            850.000000           845.000000                    9.000000        6.000000   \n",
       "\n",
       "        tot_coll_amt   tot_cur_bal    open_acc_6m    open_act_il    open_il_12m    open_il_24m  mths_since_rcnt_il  total_bal_il        il_util    open_rv_12m    open_rv_24m     max_bal_bc  \\\n",
       "count  200000.000000  2.000000e+05  200000.000000  200000.000000  200000.000000  200000.000000       200000.000000  2.000000e+05  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean      230.022100  1.334342e+05       1.050920       2.714855       0.873715       1.915005           19.761910  3.351007e+04      70.205415       1.262295       2.713755    5505.012450   \n",
       "std      1775.613015  1.492501e+05       1.189981       2.953508       1.056642       2.005857           25.708152  4.046119e+04      23.289368       1.358994       2.337575    5174.260522   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000       0.000000       0.000000            0.000000  0.000000e+00       0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000  2.936775e+04       0.000000       1.000000       0.000000       0.000000            6.000000  8.806750e+03      57.000000       0.000000       1.000000    2213.000000   \n",
       "50%         0.000000  7.298800e+04       1.000000       2.000000       1.000000       1.000000           12.000000  2.232000e+04      74.000000       1.000000       2.000000    4224.000000   \n",
       "75%         0.000000  1.972862e+05       2.000000       3.000000       1.000000       3.000000           22.000000  4.353500e+04      86.000000       2.000000       4.000000    7206.000000   \n",
       "max    199433.000000  3.258254e+06      16.000000      48.000000      20.000000      39.000000          446.000000  1.547285e+06     558.000000      22.000000      45.000000  301210.000000   \n",
       "\n",
       "            all_util  total_rev_hi_lim         inq_fi    total_cu_tl   inq_last_12m  acc_open_past_24mths    avg_cur_bal  bc_open_to_buy        bc_util  chargeoff_within_12_mths    delinq_amnt  \\\n",
       "count  200000.000000      2.000000e+05  200000.000000  200000.000000  200000.000000         200000.000000  200000.000000   200000.000000  200000.000000             200000.000000  200000.000000   \n",
       "mean       61.995210      3.119424e+04       1.167065       1.669000       2.407435              4.898570   12652.200355     9305.872275      61.043219                  0.008975      16.915020   \n",
       "std        19.674457      3.094635e+04       1.683867       2.932574       2.615008              3.280455   15288.478032    14277.046880      28.251856                  0.104616     943.077677   \n",
       "min         0.000000      0.000000e+00       0.000000       0.000000       0.000000              0.000000       0.000000        0.000000       0.000000                  0.000000       0.000000   \n",
       "25%        50.000000      1.360000e+04       0.000000       0.000000       1.000000              3.000000    3009.000000     1327.000000      39.600000                  0.000000       0.000000   \n",
       "50%        64.000000      2.320000e+04       1.000000       0.000000       2.000000              4.000000    6807.000000     4280.000000      64.700000                  0.000000       0.000000   \n",
       "75%        76.000000      3.860000e+04       2.000000       2.000000       3.000000              7.000000   17392.250000    11166.000000      86.000000                  0.000000       0.000000   \n",
       "max       168.000000      1.314900e+06      28.000000      48.000000      32.000000             50.000000  497484.000000   293031.000000     190.600000                  6.000000  249925.000000   \n",
       "\n",
       "       mo_sin_old_il_acct  mo_sin_old_rev_tl_op  mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl       mort_acc  mths_since_recent_bc  mths_since_recent_inq  mths_since_recent_revol_delinq  \\\n",
       "count       200000.000000         200000.000000          200000.000000   200000.000000  200000.000000         200000.000000          200000.000000                    200000.00000   \n",
       "mean           123.496620            177.572560              12.592685        7.572270       1.583020             23.051050               7.020060                        41.13807   \n",
       "std             53.847389             94.626771              15.829046        8.539039       1.974375             30.106178               6.059382                        21.84772   \n",
       "min              0.000000              3.000000               0.000000        0.000000       0.000000              0.000000               0.000000                         0.00000   \n",
       "25%             93.000000            114.000000               4.000000        3.000000       0.000000              6.000000               2.000000                        24.00000   \n",
       "50%            128.000000            160.000000               8.000000        5.000000       1.000000             13.000000               5.000000                        39.00000   \n",
       "75%            151.000000            226.000000              15.000000       10.000000       3.000000             27.000000              11.000000                        59.00000   \n",
       "max            724.000000            804.000000             324.000000      314.000000      32.000000            538.000000              25.000000                       202.00000   \n",
       "\n",
       "       num_accts_ever_120_pd  num_actv_bc_tl    num_bc_sats      num_bc_tl  num_rev_tl_bal_gt_0   num_tl_30dpd  num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  percent_bc_gt_75  \\\n",
       "count          200000.000000   200000.000000  200000.000000  200000.000000        200000.000000  200000.000000       200000.000000       200000.000000   200000.000000     200000.000000   \n",
       "mean                0.522660        3.702345       4.719860       7.997870             5.726970       0.003425            0.088390            2.271730       94.162227         46.697567   \n",
       "std                 1.333422        2.268906       2.960616       4.750692             3.267695       0.062636            0.485539            1.894223        8.728537         36.143285   \n",
       "min                 0.000000        0.000000       0.000000       0.000000             0.000000       0.000000            0.000000            0.000000        6.700000          0.000000   \n",
       "25%                 0.000000        2.000000       3.000000       5.000000             3.000000       0.000000            0.000000            1.000000       91.300000         14.300000   \n",
       "50%                 0.000000        3.000000       4.000000       7.000000             5.000000       0.000000            0.000000            2.000000       97.900000         50.000000   \n",
       "75%                 0.000000        5.000000       6.000000      10.000000             7.000000       0.000000            0.000000            3.000000      100.000000         75.000000   \n",
       "max                34.000000       30.000000      46.000000      61.000000            39.000000       4.000000           20.000000           25.000000      100.000000        100.000000   \n",
       "\n",
       "       pub_rec_bankruptcies      tax_liens  total_bc_limit  fico_range_mean  sub_grade_num  emp_length_num  \n",
       "count         200000.000000  200000.000000   200000.000000    200000.000000  200000.000000   200000.000000  \n",
       "mean               0.142080       0.054800    20540.207830       695.489473      12.822720        5.946410  \n",
       "std                0.386451       0.436312    20559.740281        30.408820       6.669401        3.699005  \n",
       "min                0.000000       0.000000        0.000000       662.000000       1.000000        0.000000  \n",
       "25%                0.000000       0.000000     7500.000000       672.000000       8.000000        2.000000  \n",
       "50%                0.000000       0.000000    14400.000000       687.000000      12.000000        6.000000  \n",
       "75%                0.000000       0.000000    26500.000000       712.000000      17.000000       10.000000  \n",
       "max                8.000000      85.000000   760000.000000       847.500000      35.000000       10.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n",
    "df.describe()\n",
    "# need to check (distribution extreme.. check after initial modeling) :  \n",
    "#    dti, total_rec_late_fee, recoveries, tot_coll_amt, mths_since_rcnt_il, il_util, max_bal_bc, avg_cur_bal,\n",
    "#    delinq_amnt, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mths_since_recent_revol_delinq, tax_liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['recoveries', 'last_pymnt_amnt','last_fico_range_high','last_fico_range_low','total_pymnt'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummification for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64      51\n",
      "float64    13\n",
      "object     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_old = df[df.columns.difference(['loan_status'])]\n",
    "y = df[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x_old, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training prediction accuracy :  0.69\n",
      "test prediction accuracy :  0.69\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(x_train, y_train)\n",
    "\n",
    "print('training prediction accuracy :  %.2f' % log.score(x_train, y_train))\n",
    "print('test prediction accuracy :  %.2f' % log.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.69\n"
     ]
    }
   ],
   "source": [
    "lr_log = LogisticRegression()\n",
    "lr_log.fit(x_train, y_train)\n",
    "lr_pred = lr_log.predict(x_test)\n",
    "\n",
    "print('accuracy : %.2f' % accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.747396965817424"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_prob = lr_log.predict_proba(x_test)\n",
    "roc_auc_score(y_test, test_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('model_v2_save_test.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Before Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy : 0.6685\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=1)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "print('rf accuracy : {0:.4f}' .format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Hyper Parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter:\n",
      " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100, 'random_state': 1}\n",
      "best prediction accuracy: 0.7010\n"
     ]
    }
   ],
   "source": [
    "### It takes very long ###\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf2_clf = RandomForestClassifier(random_state=1)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],    \n",
    "    'max_depth': [6,8,10],\n",
    "    'min_samples_leaf': [8,12,18],\n",
    "    'min_samples_split': [8,12,18],\n",
    "    \"random_state\": [1]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "rf_grid_cv = GridSearchCV(rf2_clf, param_grid=rf_params, cv=5)\n",
    "rf_grid_cv.fit(x_train,y_train)\n",
    "\n",
    "print('best parameter:\\n', rf_grid_cv.best_params_)\n",
    "print('best prediction accuracy: {0:.4f}'.format(rf_grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf3 accuracy : 0.7011\n"
     ]
    }
   ],
   "source": [
    "### test with best param + n_estimators increase\n",
    "rf3_clf = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8,\n",
    "                                min_samples_split=8, random_state=1)\n",
    "rf3_clf.fit(x_train, y_train)\n",
    "rf3_pred = rf3_clf.predict(x_test)\n",
    "\n",
    "print('rf3 accuracy : {0:.4f}' .format(accuracy_score(y_test, rf3_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_settlement_flag_Y    0.176717\n",
      "sub_grade_num             0.137189\n",
      "int_rate                  0.134793\n",
      "total_rec_late_fee        0.100565\n",
      "term_ 60 months           0.061201\n",
      "grade_B                   0.028728\n",
      "fico_range_mean           0.027453\n",
      "grade_E                   0.022417\n",
      "total_rec_int             0.022264\n",
      "dti                       0.020023\n",
      "grade_D                   0.018276\n",
      "avg_cur_bal               0.015258\n",
      "loan_amnt                 0.014067\n",
      "installment               0.012748\n",
      "grade_C                   0.012210\n",
      "bc_open_to_buy            0.011602\n",
      "tot_cur_bal               0.010211\n",
      "grade_F                   0.009475\n",
      "acc_open_past_24mths      0.009404\n",
      "annual_inc                0.009160\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_imp = rf3_clf.feature_importances_\n",
    "feature_imp = pd.Series(feature_imp, index=x_train.columns)\n",
    "feature_top20 = feature_imp.sort_values(ascending=False)[:20]\n",
    "print(feature_top20)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature Importance (top20)')\n",
    "sns.barplot(x=feature_top20, y=feature_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### * Before Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm accuracy : 0.7234\n",
      "gbm running time : 100.1 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=1)\n",
    "gb_clf.fit(x_train, y_train)\n",
    "gb_pred = gb_clf.predict(x_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('gbm accuracy : {0:.4f}'.format(gb_accuracy))\n",
    "print('gbm running time : {0:.1f} seconds '.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### * Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 222.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter:\n",
      " {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "best prediction accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "gb2_clf = GradientBoostingClassifier(random_state=1)\n",
    "gb_params = {\n",
    "    'n_estimators': [100,500],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "gb_grid_cv = GridSearchCV(gb2_clf, param_grid=gb_params, cv=10, verbose=1)\n",
    "gb_grid_cv.fit(x_train, y_train)\n",
    "\n",
    "print('best parameter:\\n', gb_grid_cv.best_params_)\n",
    "print('best prediction accuracy: {0:.4f}'.format(gb_grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM accuracy(After tuning) : 0.7366\n"
     ]
    }
   ],
   "source": [
    "### test with best param \n",
    "gb3_pred = gb_grid_cv.best_estimator_.predict(x_test)\n",
    "gb3_accuracy = accuracy_score(y_test, gb3_pred)\n",
    "\n",
    "print('GBM accuracy(After tuning) : {0:.4f}' .format(gb3_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y_train)\n",
    "y_train_xgb = label_encoder.transform(y_train)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y_test)\n",
    "y_test_xgb = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train, label=y_train_xgb)\n",
    "dtest = xgb.DMatrix(data=x_test, label=y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'max_depth':3, 'eta':0.1, 'objective':'binary:logistic', 'eval_metric':'logloss', \n",
    "              'early_stoppings':100}\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.676412\teval-logloss:0.676642\n",
      "[1]\ttrain-logloss:0.662649\teval-logloss:0.6631\n",
      "[2]\ttrain-logloss:0.651036\teval-logloss:0.651705\n",
      "[3]\ttrain-logloss:0.641144\teval-logloss:0.641959\n",
      "[4]\ttrain-logloss:0.632672\teval-logloss:0.633706\n",
      "[5]\ttrain-logloss:0.625469\teval-logloss:0.626627\n",
      "[6]\ttrain-logloss:0.619169\teval-logloss:0.620424\n",
      "[7]\ttrain-logloss:0.613645\teval-logloss:0.615077\n",
      "[8]\ttrain-logloss:0.609012\teval-logloss:0.610443\n",
      "[9]\ttrain-logloss:0.604744\teval-logloss:0.606312\n",
      "[10]\ttrain-logloss:0.601084\teval-logloss:0.602767\n",
      "[11]\ttrain-logloss:0.597886\teval-logloss:0.59967\n",
      "[12]\ttrain-logloss:0.59498\teval-logloss:0.596807\n",
      "[13]\ttrain-logloss:0.592086\teval-logloss:0.593986\n",
      "[14]\ttrain-logloss:0.589773\teval-logloss:0.591697\n",
      "[15]\ttrain-logloss:0.587694\teval-logloss:0.589731\n",
      "[16]\ttrain-logloss:0.585553\teval-logloss:0.587656\n",
      "[17]\ttrain-logloss:0.583829\teval-logloss:0.586033\n",
      "[18]\ttrain-logloss:0.582271\teval-logloss:0.584516\n",
      "[19]\ttrain-logloss:0.580586\teval-logloss:0.582869\n",
      "[20]\ttrain-logloss:0.579089\teval-logloss:0.581392\n",
      "[21]\ttrain-logloss:0.577811\teval-logloss:0.580221\n",
      "[22]\ttrain-logloss:0.576497\teval-logloss:0.57893\n",
      "[23]\ttrain-logloss:0.575148\teval-logloss:0.577663\n",
      "[24]\ttrain-logloss:0.574061\teval-logloss:0.576582\n",
      "[25]\ttrain-logloss:0.573075\teval-logloss:0.575664\n",
      "[26]\ttrain-logloss:0.572037\teval-logloss:0.574564\n",
      "[27]\ttrain-logloss:0.57111\teval-logloss:0.573658\n",
      "[28]\ttrain-logloss:0.570211\teval-logloss:0.572747\n",
      "[29]\ttrain-logloss:0.569328\teval-logloss:0.571838\n",
      "[30]\ttrain-logloss:0.56855\teval-logloss:0.571105\n",
      "[31]\ttrain-logloss:0.567687\teval-logloss:0.570293\n",
      "[32]\ttrain-logloss:0.566997\teval-logloss:0.569535\n",
      "[33]\ttrain-logloss:0.566097\teval-logloss:0.568728\n",
      "[34]\ttrain-logloss:0.565466\teval-logloss:0.568129\n",
      "[35]\ttrain-logloss:0.564749\teval-logloss:0.567375\n",
      "[36]\ttrain-logloss:0.564014\teval-logloss:0.566625\n",
      "[37]\ttrain-logloss:0.563281\teval-logloss:0.565991\n",
      "[38]\ttrain-logloss:0.56274\teval-logloss:0.56546\n",
      "[39]\ttrain-logloss:0.562225\teval-logloss:0.564916\n",
      "[40]\ttrain-logloss:0.56129\teval-logloss:0.564024\n",
      "[41]\ttrain-logloss:0.560654\teval-logloss:0.563414\n",
      "[42]\ttrain-logloss:0.56018\teval-logloss:0.562994\n",
      "[43]\ttrain-logloss:0.559329\teval-logloss:0.56215\n",
      "[44]\ttrain-logloss:0.55853\teval-logloss:0.561414\n",
      "[45]\ttrain-logloss:0.558067\teval-logloss:0.560975\n",
      "[46]\ttrain-logloss:0.557392\teval-logloss:0.560441\n",
      "[47]\ttrain-logloss:0.556261\teval-logloss:0.559449\n",
      "[48]\ttrain-logloss:0.555637\teval-logloss:0.558927\n",
      "[49]\ttrain-logloss:0.55521\teval-logloss:0.558472\n",
      "[50]\ttrain-logloss:0.554601\teval-logloss:0.557916\n",
      "[51]\ttrain-logloss:0.554135\teval-logloss:0.55753\n",
      "[52]\ttrain-logloss:0.553737\teval-logloss:0.557155\n",
      "[53]\ttrain-logloss:0.553262\teval-logloss:0.556675\n",
      "[54]\ttrain-logloss:0.552924\teval-logloss:0.556302\n",
      "[55]\ttrain-logloss:0.552551\teval-logloss:0.556003\n",
      "[56]\ttrain-logloss:0.551918\teval-logloss:0.555481\n",
      "[57]\ttrain-logloss:0.551085\teval-logloss:0.554691\n",
      "[58]\ttrain-logloss:0.550397\teval-logloss:0.554104\n",
      "[59]\ttrain-logloss:0.550094\teval-logloss:0.553848\n",
      "[60]\ttrain-logloss:0.549672\teval-logloss:0.553438\n",
      "[61]\ttrain-logloss:0.549274\teval-logloss:0.553097\n",
      "[62]\ttrain-logloss:0.548479\teval-logloss:0.552361\n",
      "[63]\ttrain-logloss:0.548217\teval-logloss:0.552075\n",
      "[64]\ttrain-logloss:0.547828\teval-logloss:0.551758\n",
      "[65]\ttrain-logloss:0.547474\teval-logloss:0.551399\n",
      "[66]\ttrain-logloss:0.547125\teval-logloss:0.551151\n",
      "[67]\ttrain-logloss:0.546462\teval-logloss:0.550496\n",
      "[68]\ttrain-logloss:0.545939\teval-logloss:0.55004\n",
      "[69]\ttrain-logloss:0.545525\teval-logloss:0.549707\n",
      "[70]\ttrain-logloss:0.54528\teval-logloss:0.549475\n",
      "[71]\ttrain-logloss:0.544751\teval-logloss:0.549036\n",
      "[72]\ttrain-logloss:0.544443\teval-logloss:0.54873\n",
      "[73]\ttrain-logloss:0.544116\teval-logloss:0.548527\n",
      "[74]\ttrain-logloss:0.5437\teval-logloss:0.548072\n",
      "[75]\ttrain-logloss:0.543481\teval-logloss:0.547897\n",
      "[76]\ttrain-logloss:0.543072\teval-logloss:0.547562\n",
      "[77]\ttrain-logloss:0.542808\teval-logloss:0.54736\n",
      "[78]\ttrain-logloss:0.542596\teval-logloss:0.547193\n",
      "[79]\ttrain-logloss:0.542266\teval-logloss:0.546877\n",
      "[80]\ttrain-logloss:0.541943\teval-logloss:0.546613\n",
      "[81]\ttrain-logloss:0.541682\teval-logloss:0.546369\n",
      "[82]\ttrain-logloss:0.541403\teval-logloss:0.546089\n",
      "[83]\ttrain-logloss:0.541223\teval-logloss:0.545959\n",
      "[84]\ttrain-logloss:0.541009\teval-logloss:0.545776\n",
      "[85]\ttrain-logloss:0.540698\teval-logloss:0.545493\n",
      "[86]\ttrain-logloss:0.540323\teval-logloss:0.545179\n",
      "[87]\ttrain-logloss:0.540111\teval-logloss:0.544976\n",
      "[88]\ttrain-logloss:0.539705\teval-logloss:0.544574\n",
      "[89]\ttrain-logloss:0.539527\teval-logloss:0.544407\n",
      "[90]\ttrain-logloss:0.539133\teval-logloss:0.544025\n",
      "[91]\ttrain-logloss:0.538654\teval-logloss:0.543607\n",
      "[92]\ttrain-logloss:0.53834\teval-logloss:0.543352\n",
      "[93]\ttrain-logloss:0.537987\teval-logloss:0.543068\n",
      "[94]\ttrain-logloss:0.537735\teval-logloss:0.542825\n",
      "[95]\ttrain-logloss:0.537499\teval-logloss:0.542647\n",
      "[96]\ttrain-logloss:0.537291\teval-logloss:0.542443\n",
      "[97]\ttrain-logloss:0.537142\teval-logloss:0.542322\n",
      "[98]\ttrain-logloss:0.536977\teval-logloss:0.542216\n",
      "[99]\ttrain-logloss:0.536847\teval-logloss:0.542098\n",
      "[100]\ttrain-logloss:0.536391\teval-logloss:0.541739\n",
      "[101]\ttrain-logloss:0.535998\teval-logloss:0.541367\n",
      "[102]\ttrain-logloss:0.535835\teval-logloss:0.541225\n",
      "[103]\ttrain-logloss:0.535623\teval-logloss:0.541073\n",
      "[104]\ttrain-logloss:0.535153\teval-logloss:0.54064\n",
      "[105]\ttrain-logloss:0.534992\teval-logloss:0.540523\n",
      "[106]\ttrain-logloss:0.534797\teval-logloss:0.540385\n",
      "[107]\ttrain-logloss:0.53462\teval-logloss:0.540255\n",
      "[108]\ttrain-logloss:0.53449\teval-logloss:0.540132\n",
      "[109]\ttrain-logloss:0.534061\teval-logloss:0.539799\n",
      "[110]\ttrain-logloss:0.533884\teval-logloss:0.539649\n",
      "[111]\ttrain-logloss:0.533613\teval-logloss:0.53943\n",
      "[112]\ttrain-logloss:0.533473\teval-logloss:0.539298\n",
      "[113]\ttrain-logloss:0.533324\teval-logloss:0.539185\n",
      "[114]\ttrain-logloss:0.533169\teval-logloss:0.539083\n",
      "[115]\ttrain-logloss:0.532874\teval-logloss:0.538811\n",
      "[116]\ttrain-logloss:0.532749\teval-logloss:0.538703\n",
      "[117]\ttrain-logloss:0.53255\teval-logloss:0.538507\n",
      "[118]\ttrain-logloss:0.532319\teval-logloss:0.538333\n",
      "[119]\ttrain-logloss:0.532167\teval-logloss:0.538235\n",
      "[120]\ttrain-logloss:0.531819\teval-logloss:0.537912\n",
      "[121]\ttrain-logloss:0.531544\teval-logloss:0.537686\n",
      "[122]\ttrain-logloss:0.53142\teval-logloss:0.537573\n",
      "[123]\ttrain-logloss:0.531275\teval-logloss:0.537459\n",
      "[124]\ttrain-logloss:0.530904\teval-logloss:0.537088\n",
      "[125]\ttrain-logloss:0.530509\teval-logloss:0.536702\n",
      "[126]\ttrain-logloss:0.530255\teval-logloss:0.53652\n",
      "[127]\ttrain-logloss:0.530116\teval-logloss:0.536448\n",
      "[128]\ttrain-logloss:0.52995\teval-logloss:0.536281\n",
      "[129]\ttrain-logloss:0.529685\teval-logloss:0.536117\n",
      "[130]\ttrain-logloss:0.529537\teval-logloss:0.536007\n",
      "[131]\ttrain-logloss:0.529378\teval-logloss:0.535884\n",
      "[132]\ttrain-logloss:0.529219\teval-logloss:0.535746\n",
      "[133]\ttrain-logloss:0.52912\teval-logloss:0.53566\n",
      "[134]\ttrain-logloss:0.528898\teval-logloss:0.535463\n",
      "[135]\ttrain-logloss:0.528768\teval-logloss:0.535338\n",
      "[136]\ttrain-logloss:0.528656\teval-logloss:0.53526\n",
      "[137]\ttrain-logloss:0.528578\teval-logloss:0.535187\n",
      "[138]\ttrain-logloss:0.528263\teval-logloss:0.534901\n",
      "[139]\ttrain-logloss:0.528114\teval-logloss:0.534765\n",
      "[140]\ttrain-logloss:0.527997\teval-logloss:0.534714\n",
      "[141]\ttrain-logloss:0.527873\teval-logloss:0.534624\n",
      "[142]\ttrain-logloss:0.527701\teval-logloss:0.534504\n",
      "[143]\ttrain-logloss:0.52756\teval-logloss:0.534393\n",
      "[144]\ttrain-logloss:0.527206\teval-logloss:0.53408\n",
      "[145]\ttrain-logloss:0.52696\teval-logloss:0.533888\n",
      "[146]\ttrain-logloss:0.526842\teval-logloss:0.5338\n",
      "[147]\ttrain-logloss:0.526708\teval-logloss:0.533725\n",
      "[148]\ttrain-logloss:0.526244\teval-logloss:0.533293\n",
      "[149]\ttrain-logloss:0.526152\teval-logloss:0.533232\n",
      "[150]\ttrain-logloss:0.525936\teval-logloss:0.533024\n",
      "[151]\ttrain-logloss:0.525845\teval-logloss:0.532951\n",
      "[152]\ttrain-logloss:0.525707\teval-logloss:0.532829\n",
      "[153]\ttrain-logloss:0.525567\teval-logloss:0.53271\n",
      "[154]\ttrain-logloss:0.525452\teval-logloss:0.532626\n",
      "[155]\ttrain-logloss:0.525334\teval-logloss:0.532539\n",
      "[156]\ttrain-logloss:0.525163\teval-logloss:0.532378\n",
      "[157]\ttrain-logloss:0.525064\teval-logloss:0.532284\n",
      "[158]\ttrain-logloss:0.52499\teval-logloss:0.532222\n",
      "[159]\ttrain-logloss:0.524901\teval-logloss:0.532146\n",
      "[160]\ttrain-logloss:0.524822\teval-logloss:0.532067\n",
      "[161]\ttrain-logloss:0.524681\teval-logloss:0.531943\n",
      "[162]\ttrain-logloss:0.524449\teval-logloss:0.531747\n",
      "[163]\ttrain-logloss:0.524358\teval-logloss:0.531683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\ttrain-logloss:0.524066\teval-logloss:0.531377\n",
      "[165]\ttrain-logloss:0.523986\teval-logloss:0.531308\n",
      "[166]\ttrain-logloss:0.523835\teval-logloss:0.531211\n",
      "[167]\ttrain-logloss:0.523722\teval-logloss:0.531145\n",
      "[168]\ttrain-logloss:0.523572\teval-logloss:0.531004\n",
      "[169]\ttrain-logloss:0.523499\teval-logloss:0.530961\n",
      "[170]\ttrain-logloss:0.523122\teval-logloss:0.530579\n",
      "[171]\ttrain-logloss:0.523049\teval-logloss:0.530508\n",
      "[172]\ttrain-logloss:0.522926\teval-logloss:0.530429\n",
      "[173]\ttrain-logloss:0.52284\teval-logloss:0.530388\n",
      "[174]\ttrain-logloss:0.522749\teval-logloss:0.530337\n",
      "[175]\ttrain-logloss:0.522579\teval-logloss:0.530185\n",
      "[176]\ttrain-logloss:0.5225\teval-logloss:0.530127\n",
      "[177]\ttrain-logloss:0.522393\teval-logloss:0.530072\n",
      "[178]\ttrain-logloss:0.522252\teval-logloss:0.529969\n",
      "[179]\ttrain-logloss:0.522173\teval-logloss:0.529946\n",
      "[180]\ttrain-logloss:0.522113\teval-logloss:0.52991\n",
      "[181]\ttrain-logloss:0.52205\teval-logloss:0.529865\n",
      "[182]\ttrain-logloss:0.521918\teval-logloss:0.529769\n",
      "[183]\ttrain-logloss:0.52179\teval-logloss:0.529697\n",
      "[184]\ttrain-logloss:0.521711\teval-logloss:0.529631\n",
      "[185]\ttrain-logloss:0.521437\teval-logloss:0.529396\n",
      "[186]\ttrain-logloss:0.521352\teval-logloss:0.529356\n",
      "[187]\ttrain-logloss:0.521276\teval-logloss:0.529296\n",
      "[188]\ttrain-logloss:0.521211\teval-logloss:0.529252\n",
      "[189]\ttrain-logloss:0.52114\teval-logloss:0.529222\n",
      "[190]\ttrain-logloss:0.52106\teval-logloss:0.529181\n",
      "[191]\ttrain-logloss:0.520781\teval-logloss:0.528908\n",
      "[192]\ttrain-logloss:0.520656\teval-logloss:0.528826\n",
      "[193]\ttrain-logloss:0.520562\teval-logloss:0.528748\n",
      "[194]\ttrain-logloss:0.520334\teval-logloss:0.528522\n",
      "[195]\ttrain-logloss:0.520116\teval-logloss:0.528324\n",
      "[196]\ttrain-logloss:0.520063\teval-logloss:0.52829\n",
      "[197]\ttrain-logloss:0.519978\teval-logloss:0.528255\n",
      "[198]\ttrain-logloss:0.519857\teval-logloss:0.528174\n",
      "[199]\ttrain-logloss:0.519744\teval-logloss:0.528095\n",
      "[200]\ttrain-logloss:0.519674\teval-logloss:0.528061\n",
      "[201]\ttrain-logloss:0.519541\teval-logloss:0.527937\n",
      "[202]\ttrain-logloss:0.519437\teval-logloss:0.527874\n",
      "[203]\ttrain-logloss:0.519391\teval-logloss:0.527836\n",
      "[204]\ttrain-logloss:0.519325\teval-logloss:0.527814\n",
      "[205]\ttrain-logloss:0.519255\teval-logloss:0.527775\n",
      "[206]\ttrain-logloss:0.519007\teval-logloss:0.527515\n",
      "[207]\ttrain-logloss:0.518867\teval-logloss:0.527438\n",
      "[208]\ttrain-logloss:0.518797\teval-logloss:0.527399\n",
      "[209]\ttrain-logloss:0.518678\teval-logloss:0.527308\n",
      "[210]\ttrain-logloss:0.518567\teval-logloss:0.527214\n",
      "[211]\ttrain-logloss:0.518498\teval-logloss:0.527191\n",
      "[212]\ttrain-logloss:0.518435\teval-logloss:0.527137\n",
      "[213]\ttrain-logloss:0.518392\teval-logloss:0.527092\n",
      "[214]\ttrain-logloss:0.5183\teval-logloss:0.527051\n",
      "[215]\ttrain-logloss:0.51825\teval-logloss:0.527012\n",
      "[216]\ttrain-logloss:0.518166\teval-logloss:0.526983\n",
      "[217]\ttrain-logloss:0.518092\teval-logloss:0.526907\n",
      "[218]\ttrain-logloss:0.518012\teval-logloss:0.52685\n",
      "[219]\ttrain-logloss:0.517871\teval-logloss:0.526738\n",
      "[220]\ttrain-logloss:0.517614\teval-logloss:0.526477\n",
      "[221]\ttrain-logloss:0.517561\teval-logloss:0.526468\n",
      "[222]\ttrain-logloss:0.517486\teval-logloss:0.526464\n",
      "[223]\ttrain-logloss:0.517423\teval-logloss:0.526436\n",
      "[224]\ttrain-logloss:0.517272\teval-logloss:0.526292\n",
      "[225]\ttrain-logloss:0.517148\teval-logloss:0.526191\n",
      "[226]\ttrain-logloss:0.517059\teval-logloss:0.526084\n",
      "[227]\ttrain-logloss:0.516985\teval-logloss:0.526044\n",
      "[228]\ttrain-logloss:0.516944\teval-logloss:0.526008\n",
      "[229]\ttrain-logloss:0.516885\teval-logloss:0.52598\n",
      "[230]\ttrain-logloss:0.516839\teval-logloss:0.52596\n",
      "[231]\ttrain-logloss:0.51677\teval-logloss:0.525916\n",
      "[232]\ttrain-logloss:0.516714\teval-logloss:0.525868\n",
      "[233]\ttrain-logloss:0.516467\teval-logloss:0.525638\n",
      "[234]\ttrain-logloss:0.516382\teval-logloss:0.52558\n",
      "[235]\ttrain-logloss:0.516299\teval-logloss:0.525513\n",
      "[236]\ttrain-logloss:0.516218\teval-logloss:0.525474\n",
      "[237]\ttrain-logloss:0.516142\teval-logloss:0.525445\n",
      "[238]\ttrain-logloss:0.515975\teval-logloss:0.525315\n",
      "[239]\ttrain-logloss:0.515912\teval-logloss:0.525297\n",
      "[240]\ttrain-logloss:0.515804\teval-logloss:0.525225\n",
      "[241]\ttrain-logloss:0.515723\teval-logloss:0.525171\n",
      "[242]\ttrain-logloss:0.515667\teval-logloss:0.525125\n",
      "[243]\ttrain-logloss:0.515602\teval-logloss:0.52508\n",
      "[244]\ttrain-logloss:0.515568\teval-logloss:0.525052\n",
      "[245]\ttrain-logloss:0.515452\teval-logloss:0.524921\n",
      "[246]\ttrain-logloss:0.515338\teval-logloss:0.524848\n",
      "[247]\ttrain-logloss:0.515277\teval-logloss:0.524827\n",
      "[248]\ttrain-logloss:0.515204\teval-logloss:0.524785\n",
      "[249]\ttrain-logloss:0.515149\teval-logloss:0.524779\n",
      "[250]\ttrain-logloss:0.515096\teval-logloss:0.524769\n",
      "[251]\ttrain-logloss:0.515042\teval-logloss:0.524731\n",
      "[252]\ttrain-logloss:0.514981\teval-logloss:0.5247\n",
      "[253]\ttrain-logloss:0.514901\teval-logloss:0.524665\n",
      "[254]\ttrain-logloss:0.514819\teval-logloss:0.524618\n",
      "[255]\ttrain-logloss:0.514713\teval-logloss:0.52455\n",
      "[256]\ttrain-logloss:0.514632\teval-logloss:0.524497\n",
      "[257]\ttrain-logloss:0.51459\teval-logloss:0.524488\n",
      "[258]\ttrain-logloss:0.514526\teval-logloss:0.52445\n",
      "[259]\ttrain-logloss:0.514494\teval-logloss:0.524426\n",
      "[260]\ttrain-logloss:0.514433\teval-logloss:0.52443\n",
      "[261]\ttrain-logloss:0.514358\teval-logloss:0.524344\n",
      "[262]\ttrain-logloss:0.514296\teval-logloss:0.524306\n",
      "[263]\ttrain-logloss:0.514243\teval-logloss:0.524287\n",
      "[264]\ttrain-logloss:0.514209\teval-logloss:0.524263\n",
      "[265]\ttrain-logloss:0.514102\teval-logloss:0.524206\n",
      "[266]\ttrain-logloss:0.514072\teval-logloss:0.524192\n",
      "[267]\ttrain-logloss:0.513946\teval-logloss:0.524109\n",
      "[268]\ttrain-logloss:0.513905\teval-logloss:0.524076\n",
      "[269]\ttrain-logloss:0.513815\teval-logloss:0.524021\n",
      "[270]\ttrain-logloss:0.513763\teval-logloss:0.523972\n",
      "[271]\ttrain-logloss:0.513725\teval-logloss:0.523947\n",
      "[272]\ttrain-logloss:0.513683\teval-logloss:0.523927\n",
      "[273]\ttrain-logloss:0.513628\teval-logloss:0.523918\n",
      "[274]\ttrain-logloss:0.513567\teval-logloss:0.523899\n",
      "[275]\ttrain-logloss:0.513409\teval-logloss:0.523775\n",
      "[276]\ttrain-logloss:0.513239\teval-logloss:0.523598\n",
      "[277]\ttrain-logloss:0.513187\teval-logloss:0.523592\n",
      "[278]\ttrain-logloss:0.513138\teval-logloss:0.523577\n",
      "[279]\ttrain-logloss:0.513001\teval-logloss:0.523468\n",
      "[280]\ttrain-logloss:0.512942\teval-logloss:0.523427\n",
      "[281]\ttrain-logloss:0.512851\teval-logloss:0.52336\n",
      "[282]\ttrain-logloss:0.512806\teval-logloss:0.523337\n",
      "[283]\ttrain-logloss:0.512756\teval-logloss:0.523305\n",
      "[284]\ttrain-logloss:0.512712\teval-logloss:0.523292\n",
      "[285]\ttrain-logloss:0.512634\teval-logloss:0.523217\n",
      "[286]\ttrain-logloss:0.512603\teval-logloss:0.523198\n",
      "[287]\ttrain-logloss:0.512546\teval-logloss:0.523174\n",
      "[288]\ttrain-logloss:0.512509\teval-logloss:0.523152\n",
      "[289]\ttrain-logloss:0.512442\teval-logloss:0.523097\n",
      "[290]\ttrain-logloss:0.512291\teval-logloss:0.522979\n",
      "[291]\ttrain-logloss:0.512262\teval-logloss:0.522967\n",
      "[292]\ttrain-logloss:0.512105\teval-logloss:0.522821\n",
      "[293]\ttrain-logloss:0.512061\teval-logloss:0.52281\n",
      "[294]\ttrain-logloss:0.511802\teval-logloss:0.522611\n",
      "[295]\ttrain-logloss:0.511722\teval-logloss:0.522554\n",
      "[296]\ttrain-logloss:0.51166\teval-logloss:0.522523\n",
      "[297]\ttrain-logloss:0.511597\teval-logloss:0.522493\n",
      "[298]\ttrain-logloss:0.511525\teval-logloss:0.522455\n",
      "[299]\ttrain-logloss:0.511438\teval-logloss:0.522416\n",
      "[300]\ttrain-logloss:0.511395\teval-logloss:0.522409\n",
      "[301]\ttrain-logloss:0.51135\teval-logloss:0.522411\n",
      "[302]\ttrain-logloss:0.511306\teval-logloss:0.522373\n",
      "[303]\ttrain-logloss:0.511077\teval-logloss:0.522191\n",
      "[304]\ttrain-logloss:0.511006\teval-logloss:0.522167\n",
      "[305]\ttrain-logloss:0.510952\teval-logloss:0.522147\n",
      "[306]\ttrain-logloss:0.510896\teval-logloss:0.522131\n",
      "[307]\ttrain-logloss:0.510849\teval-logloss:0.522106\n",
      "[308]\ttrain-logloss:0.510792\teval-logloss:0.522066\n",
      "[309]\ttrain-logloss:0.510682\teval-logloss:0.52199\n",
      "[310]\ttrain-logloss:0.510596\teval-logloss:0.521925\n",
      "[311]\ttrain-logloss:0.510553\teval-logloss:0.521917\n",
      "[312]\ttrain-logloss:0.51051\teval-logloss:0.5219\n",
      "[313]\ttrain-logloss:0.510466\teval-logloss:0.521876\n",
      "[314]\ttrain-logloss:0.510413\teval-logloss:0.521843\n",
      "[315]\ttrain-logloss:0.510385\teval-logloss:0.52184\n",
      "[316]\ttrain-logloss:0.510345\teval-logloss:0.521832\n",
      "[317]\ttrain-logloss:0.510311\teval-logloss:0.521832\n",
      "[318]\ttrain-logloss:0.510266\teval-logloss:0.521787\n",
      "[319]\ttrain-logloss:0.510226\teval-logloss:0.521764\n",
      "[320]\ttrain-logloss:0.510178\teval-logloss:0.521739\n",
      "[321]\ttrain-logloss:0.510156\teval-logloss:0.521728\n",
      "[322]\ttrain-logloss:0.510018\teval-logloss:0.521618\n",
      "[323]\ttrain-logloss:0.509953\teval-logloss:0.521584\n",
      "[324]\ttrain-logloss:0.509877\teval-logloss:0.521542\n",
      "[325]\ttrain-logloss:0.509852\teval-logloss:0.521533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326]\ttrain-logloss:0.509731\teval-logloss:0.521406\n",
      "[327]\ttrain-logloss:0.509699\teval-logloss:0.521399\n",
      "[328]\ttrain-logloss:0.509652\teval-logloss:0.521373\n",
      "[329]\ttrain-logloss:0.509602\teval-logloss:0.521357\n",
      "[330]\ttrain-logloss:0.509519\teval-logloss:0.521318\n",
      "[331]\ttrain-logloss:0.509482\teval-logloss:0.521309\n",
      "[332]\ttrain-logloss:0.50942\teval-logloss:0.521298\n",
      "[333]\ttrain-logloss:0.509378\teval-logloss:0.521277\n",
      "[334]\ttrain-logloss:0.509322\teval-logloss:0.521242\n",
      "[335]\ttrain-logloss:0.509209\teval-logloss:0.52118\n",
      "[336]\ttrain-logloss:0.509166\teval-logloss:0.521181\n",
      "[337]\ttrain-logloss:0.509094\teval-logloss:0.521111\n",
      "[338]\ttrain-logloss:0.509009\teval-logloss:0.521037\n",
      "[339]\ttrain-logloss:0.508988\teval-logloss:0.521019\n",
      "[340]\ttrain-logloss:0.508922\teval-logloss:0.520982\n",
      "[341]\ttrain-logloss:0.508862\teval-logloss:0.520955\n",
      "[342]\ttrain-logloss:0.508821\teval-logloss:0.52095\n",
      "[343]\ttrain-logloss:0.508763\teval-logloss:0.520905\n",
      "[344]\ttrain-logloss:0.508676\teval-logloss:0.520841\n",
      "[345]\ttrain-logloss:0.508631\teval-logloss:0.520819\n",
      "[346]\ttrain-logloss:0.508548\teval-logloss:0.520783\n",
      "[347]\ttrain-logloss:0.508492\teval-logloss:0.520762\n",
      "[348]\ttrain-logloss:0.508438\teval-logloss:0.520733\n",
      "[349]\ttrain-logloss:0.508383\teval-logloss:0.52072\n",
      "[350]\ttrain-logloss:0.508327\teval-logloss:0.520683\n",
      "[351]\ttrain-logloss:0.508295\teval-logloss:0.52068\n",
      "[352]\ttrain-logloss:0.508135\teval-logloss:0.520529\n",
      "[353]\ttrain-logloss:0.508032\teval-logloss:0.520471\n",
      "[354]\ttrain-logloss:0.507987\teval-logloss:0.520457\n",
      "[355]\ttrain-logloss:0.507938\teval-logloss:0.520431\n",
      "[356]\ttrain-logloss:0.507882\teval-logloss:0.520413\n",
      "[357]\ttrain-logloss:0.507841\teval-logloss:0.520422\n",
      "[358]\ttrain-logloss:0.507819\teval-logloss:0.52041\n",
      "[359]\ttrain-logloss:0.507793\teval-logloss:0.520404\n",
      "[360]\ttrain-logloss:0.507692\teval-logloss:0.520355\n",
      "[361]\ttrain-logloss:0.507635\teval-logloss:0.520325\n",
      "[362]\ttrain-logloss:0.507592\teval-logloss:0.520306\n",
      "[363]\ttrain-logloss:0.50755\teval-logloss:0.5203\n",
      "[364]\ttrain-logloss:0.507508\teval-logloss:0.520278\n",
      "[365]\ttrain-logloss:0.507488\teval-logloss:0.520262\n",
      "[366]\ttrain-logloss:0.507438\teval-logloss:0.520238\n",
      "[367]\ttrain-logloss:0.5074\teval-logloss:0.520216\n",
      "[368]\ttrain-logloss:0.507352\teval-logloss:0.520213\n",
      "[369]\ttrain-logloss:0.507319\teval-logloss:0.520199\n",
      "[370]\ttrain-logloss:0.507226\teval-logloss:0.520152\n",
      "[371]\ttrain-logloss:0.50717\teval-logloss:0.520128\n",
      "[372]\ttrain-logloss:0.50709\teval-logloss:0.520057\n",
      "[373]\ttrain-logloss:0.507016\teval-logloss:0.520023\n",
      "[374]\ttrain-logloss:0.506927\teval-logloss:0.51998\n",
      "[375]\ttrain-logloss:0.506875\teval-logloss:0.51997\n",
      "[376]\ttrain-logloss:0.50683\teval-logloss:0.519951\n",
      "[377]\ttrain-logloss:0.506677\teval-logloss:0.519749\n",
      "[378]\ttrain-logloss:0.506602\teval-logloss:0.519696\n",
      "[379]\ttrain-logloss:0.506555\teval-logloss:0.519688\n",
      "[380]\ttrain-logloss:0.506481\teval-logloss:0.51964\n",
      "[381]\ttrain-logloss:0.506431\teval-logloss:0.519619\n",
      "[382]\ttrain-logloss:0.506366\teval-logloss:0.519574\n",
      "[383]\ttrain-logloss:0.506278\teval-logloss:0.519527\n",
      "[384]\ttrain-logloss:0.506229\teval-logloss:0.519482\n",
      "[385]\ttrain-logloss:0.506194\teval-logloss:0.519474\n",
      "[386]\ttrain-logloss:0.506146\teval-logloss:0.519454\n",
      "[387]\ttrain-logloss:0.506114\teval-logloss:0.519426\n",
      "[388]\ttrain-logloss:0.506082\teval-logloss:0.519415\n",
      "[389]\ttrain-logloss:0.506048\teval-logloss:0.519413\n",
      "[390]\ttrain-logloss:0.506031\teval-logloss:0.519397\n",
      "[391]\ttrain-logloss:0.505991\teval-logloss:0.519352\n",
      "[392]\ttrain-logloss:0.505958\teval-logloss:0.519352\n",
      "[393]\ttrain-logloss:0.505912\teval-logloss:0.519324\n",
      "[394]\ttrain-logloss:0.505878\teval-logloss:0.519304\n",
      "[395]\ttrain-logloss:0.505844\teval-logloss:0.519299\n",
      "[396]\ttrain-logloss:0.505812\teval-logloss:0.519301\n",
      "[397]\ttrain-logloss:0.505762\teval-logloss:0.519279\n",
      "[398]\ttrain-logloss:0.505728\teval-logloss:0.519271\n",
      "[399]\ttrain-logloss:0.505692\teval-logloss:0.519245\n"
     ]
    }
   ],
   "source": [
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "xgb_model = xgb.train(params = xgb_params, dtrain=dtrain, num_boost_round=num_rounds, evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "xgb_preds = [1 if x>0.5 else 0 for x in pred_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test_xgb, pred)\n",
    "    accuracy = accuracy_score(y_test_xgb , pred)\n",
    "    precision = precision_score(y_test_xgb , pred)\n",
    "    recall = recall_score(y_test_xgb , pred)\n",
    "    print('confusion matrix')\n",
    "    print(confusion)\n",
    "    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[12085  6418]\n",
      " [ 4203 17294]]\n",
      "Accuracy: 0.7345, Precision: 0.7293, Recall: 0.8045\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test_xgb, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
